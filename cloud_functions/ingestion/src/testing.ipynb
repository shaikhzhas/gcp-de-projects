{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaikhygalizhassulan/Library/Python/3.9/lib/python/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.18) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import NotFound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/shaikhygalizhassulan/terraform-key.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the data pipeline...\n",
      "Initializing the external table...\n",
      "Deleted table 'sustainable-data-platform.sdp.sample_sustainability_data_with_schema'.\n",
      "Table 'sustainable-data-platform.sdp.sample_sustainability_data_with_schema' is updated with data from 'gs://sdp-dev/sample_sustainability_*.csv'.\n",
      "External table initialization complete.\n",
      "Transforming the core layer...\n",
      "Core layer transformation complete.\n",
      "Transforming the datamart layer...\n",
      "Datamart layer transformation complete.\n",
      "Data pipeline complete.\n"
     ]
    }
   ],
   "source": [
    "# import functions_framework\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import NotFound\n",
    "\n",
    "PROJECT_ID = \"sustainable-data-platform\"\n",
    "\n",
    "def initialize_external_table():\n",
    "    print(\"Initializing the external table...\")\n",
    "    # Initialize a BigQuery client\n",
    "    client = bigquery.Client(PROJECT_ID)\n",
    "\n",
    "    # Define the table ID\n",
    "    table_id = \"sustainable-data-platform.sdp.sample_sustainability_data_with_schema\"\n",
    "\n",
    "    # Attempt to delete the table if it exists\n",
    "    try:\n",
    "        client.delete_table(table_id, not_found_ok=True)  # Make an API request.\n",
    "        print(f\"Deleted table '{table_id}'.\")\n",
    "    except NotFound:\n",
    "        print(f\"Table '{table_id}' not found.\")\n",
    "\n",
    "    # Define the job configuration for loading data\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        source_format=bigquery.SourceFormat.CSV,\n",
    "        skip_leading_rows=1,  # Skip the header row\n",
    "        autodetect=True,  # Automatically detect the schema\n",
    "    )\n",
    "\n",
    "    # Define the URI of the source file in GCS\n",
    "    uri = \"gs://sdp-dev/sample_sustainability_*.csv\"\n",
    "\n",
    "    # Start the load job\n",
    "    load_job = client.load_table_from_uri(\n",
    "        uri,\n",
    "        table_id,\n",
    "        job_config=job_config\n",
    "    )\n",
    "\n",
    "    # Wait for the load job to complete\n",
    "    load_job.result()\n",
    "\n",
    "    print(f\"Table '{table_id}' is updated with data from '{uri}'.\")\n",
    "    print(\"External table initialization complete.\")\n",
    "\n",
    "def transform_core_layer():\n",
    "    print(\"Transforming the core layer...\")\n",
    "    # Initialize a BigQuery client\n",
    "    client = bigquery.Client(PROJECT_ID)\n",
    "\n",
    "    # Define the SQL query, merging the data from the two tables\n",
    "    query = \"\"\"\n",
    "    MERGE INTO `sustainable-data-platform.sdp.sample_sustainability_data_with_schema_core` AS TARGET\n",
    "    USING (\n",
    "    SELECT\n",
    "        Year,\n",
    "        Country,\n",
    "        AVG(CO2_Emissions) AS CO2_Emissions,\n",
    "        AVG(Renewable_Energy_Consumption) AS Renewable_Energy_Consumption,\n",
    "        AVG(Population_Millions) AS Population_Millions\n",
    "    FROM\n",
    "        `sustainable-data-platform.sdp.sample_sustainability_data_with_schema`\n",
    "    GROUP BY\n",
    "        Year, Country\n",
    "    ) AS SOURCE\n",
    "    ON \n",
    "    TARGET.Year = SOURCE.Year AND\n",
    "    TARGET.Country = SOURCE.Country\n",
    "    WHEN MATCHED THEN\n",
    "    UPDATE SET \n",
    "        TARGET.CO2_Emissions = SOURCE.CO2_Emissions,\n",
    "        TARGET.Renewable_Energy_Consumption = SOURCE.Renewable_Energy_Consumption,\n",
    "        TARGET.Population_Millions = SOURCE.Population_Millions\n",
    "    WHEN NOT MATCHED THEN\n",
    "    INSERT (Year, Country, CO2_Emissions, Renewable_Energy_Consumption, Population_Millions)\n",
    "    VALUES (SOURCE.Year, SOURCE.Country, SOURCE.CO2_Emissions, SOURCE.Renewable_Energy_Consumption, SOURCE.Population_Millions);\n",
    "    \"\"\"\n",
    "    query_job = client.query(query)  # API request\n",
    "    query_job.result()  # Wait for the job to complete\n",
    "    print(\"Core layer transformation complete.\")\n",
    "\n",
    "def transform_datamart_layer():\n",
    "    print(\"Transforming the datamart layer...\")\n",
    "    # Initialize a BigQuery client\n",
    "    client = bigquery.Client(PROJECT_ID)\n",
    "    query = \"\"\"\n",
    "    MERGE INTO `sustainable-data-platform.sdp.sample_sustainability_data_with_schema_datamart` AS TARGET\n",
    "    USING (\n",
    "    SELECT\n",
    "        Year,\n",
    "        Country,\n",
    "        AVG(CO2_Emissions) AS CO2_Emissions,\n",
    "        AVG(Renewable_Energy_Consumption) AS Renewable_Energy_Consumption,\n",
    "        AVG(Population_Millions) AS Population_Millions\n",
    "    FROM\n",
    "        `sustainable-data-platform.sdp.sample_sustainability_data_with_schema_core`\n",
    "    GROUP BY\n",
    "        Year, Country\n",
    "    ) AS SOURCE\n",
    "    ON \n",
    "    TARGET.Year = SOURCE.Year AND\n",
    "    TARGET.Country = SOURCE.Country\n",
    "    WHEN MATCHED THEN\n",
    "    UPDATE SET \n",
    "        TARGET.CO2_Emissions = SOURCE.CO2_Emissions,\n",
    "        TARGET.Renewable_Energy_Consumption = SOURCE.Renewable_Energy_Consumption,\n",
    "        TARGET.Population_Millions = SOURCE.Population_Millions\n",
    "    WHEN NOT MATCHED THEN\n",
    "    INSERT (Year, Country, CO2_Emissions, Renewable_Energy_Consumption, Population_Millions)\n",
    "    VALUES (SOURCE.Year, SOURCE.Country, SOURCE.CO2_Emissions, SOURCE.Renewable_Energy_Consumption, SOURCE.Population_Millions);\n",
    "    \"\"\"\n",
    "    query_job = client.query(query)  # API request\n",
    "    query_job.result()  # Wait for the job to complete\n",
    "    print(\"Datamart layer transformation complete.\")\n",
    "\n",
    "print(\"Starting the data pipeline...\")\n",
    "initialize_external_table()\n",
    "transform_core_layer()\n",
    "transform_datamart_layer()\n",
    "print(\"Data pipeline complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'sustainable-data-platform.sdp.sample_sustainability_data_with_schema' is updated with data from 'gs://sdp-dev/sample_sustainability_*.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the job configuration for loading data\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    "    skip_leading_rows=1,  # Skip the header row\n",
    "    autodetect=True,  # Automatically detect the schema\n",
    ")\n",
    "\n",
    "# Define the URI of the source file in GCS\n",
    "uri = \"gs://sdp-dev/sample_sustainability_*.csv\"\n",
    "\n",
    "# Start the load job\n",
    "load_job = client.load_table_from_uri(\n",
    "    uri,\n",
    "    table_id,\n",
    "    job_config=job_config\n",
    ")\n",
    "\n",
    "# Wait for the load job to complete\n",
    "load_job.result()\n",
    "\n",
    "print(f\"Table '{table_id}' is updated with data from '{uri}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
